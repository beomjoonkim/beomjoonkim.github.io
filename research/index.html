 <br>
           <br>
           1. what knowledge we should build in, and what we should learn
           <br>
           Contrary to popular data-driven approaches, I do not believe that a robot should learn everything from
           data.  This argument is founded on two reasons. The first is wasted effort on rediscovery.
           We as humans have developed a huge amount of
           knowledge - classical mechanics, fluid dynamics, information theory, to name a few. It would be a waste
           of resource if a robot must re-discover this from data. The second has to do with several experimental
           results from psychology and neuroscience that indicates that even humans, the most intelligent
           creature that we know, come with innate knowledge from which we build our knowledge. If it is our premise
           that we should build in knowledge, then the question is what.
           <br>
           <br>
           2. how we should build in the knowledge or learn them from experience.
           <br>
           <br>
           3. how to use
           the acquired knowledge, either learned or hand-coded, effectively.
           <br>
           <br>
           <br>

<!DOCTYPE html>
<html>
<title> The iMSquared Lab </title>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="shortcut icon" type="image/x-icon" href="../images/favicon.ico" />
<br>

<!-- Navbar (sit on top) -->
<div class="w3-top">
  <div class="w3-bar w3-white w3-wide w3-padding w3-card">
    <a href="../" class="w3-bar-item w3-button"><b> iM^2 </b> - Intelligent Mobile Manipulation Lab</a>
    <!-- Float links to the right. Hide them on small screens -->
    <div class="w3-right w3-hide-small">
      <a href="#Research" class="w3-bar-item w3-button">Research</a>
      <a href="../people/" class="w3-bar-item w3-button">People</a>
      <a href="../publications/" class="w3-bar-item w3-button">Publications</a>
    </div>
  </div>
</div>

<style>
.aligncenter {
    text-align: center;
}
</style>

<style>
p {
  font-size:17.6px;
  margin-left:250px;
  margin-right:250px;
  font-family:Cabin
}
</style>
<div class="w3-content w3-padding" style="max-width:1564px">
  <div class="w3-container w3-padding-32" id="about">
  <p>
  We develop artificial intelligence of mobile-manipulation robots to endow them with the capabilities that
    come naturally to humans. Our methodology is to
  tightly integrate learning, reasoning, and modelling to create adaptive robots that utilize both
  prior knowledge and experience to effectively operate in novel and unstructured environments.
  </p>

  <p> <strong> Perception for sequential robot manipulation  </strong> </p>
  <p style="text-align:center;">
  <iframe width="360" height="215" src="https://www.youtube.com/embed/7sIypyaZtMk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <iframe width="360" height="215" src="https://www.youtube.com/embed/CKOTcHZe4WU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <p> One fundamental capability of a mobile-manipulator is computing a sequence of manipulation
    motions to move an object given a perceptual input. While deep learning techniques has had
    significant impact on computer vision tasks,
    their impact on manipulation planning has been limited due to challenges
    that arise from motion feasibility, sequentiality, and representation. We are developing
    an integrated learning and reasoning methods that use machine learning to
    process high-dimensional sensory data and robot motion planning and control algorithms to compute
    a sequential manipulation motions.  </p>
  </p>

  <p> <strong> Learning to guide task and motion planning </strong> </p>
  <p style="text-align:center;">
      <img src="../images/tamp_example.png" alt="TAMP examples" height="150">
    <p> AlphaGo had a tremendous success in the game of Go by integrating planning
    with reinforcement learning (RL). Planning enabled the Go-playing agent
    to deliberately choose a move among many choices, while RL enabled the agent to prioritize promising moves
    efficiently from experience. We apply this insight to task and motion planning problems,
    where the robot has to manipulate multiple objects to achieve a high-level goal. In particular,
    we are developing representation, planning, and learning algorithms to deal with the fact that
    the robot faces a real-world environment instead of a game board.
    </p>
  </p>



</div>
</div>



</body>
</html>
